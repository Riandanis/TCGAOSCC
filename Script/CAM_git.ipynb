{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import cv2, torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from skimage import img_as_float,io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path= '/home/DL-based-Tumor-Classification/Datasets/Newest_case/Oral+Carcinoma'\n",
    "def_path = default_path + '/img_fold0'\n",
    "final_conv = 'conv3'\n",
    "num_epochs = 50\n",
    "batch_size = 400\n",
    "learning_rate = 0.0001\n",
    "imsize = 98\n",
    "conv1_kernel = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop2D): Dropout2d(p=0.25, inplace=False)\n",
       "  (vp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=36864, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_of_classes):\n",
    "        super(Net, self).__init__()\n",
    "        # input image channel, output channels, kernel size square convolution\n",
    "        # kernel\n",
    "        # input size = 28//96 output size = 28//96\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=conv1_kernel, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # input size = 14//48 output size = 6//48\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        # input size = 6//24, output size = 3//24\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False)\n",
    "        self.vp = nn.MaxPool2d(kernel_size=2, padding=0, stride=2)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256*12*12, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, num_of_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.bn1(self.vp(self.conv1(x))))\n",
    "        x = F.relu(self.bn2(self.vp(self.conv2(x))))\n",
    "        x = F.relu(self.bn3(self.vp(self.conv3(x))))\n",
    "        x = self.drop2D(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(num_of_classes=6)\n",
    "net = net.double()\n",
    "# net = nn.DataParallel(net)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pretrained Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(def_path + '/network_0505_th1.pth')\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "# load params\n",
    "net.load_state_dict(new_state_dict)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_path = default_path + '/img_fold0'\n",
    "train_csv_path = def_path + '/train/labels_train.csv'\n",
    "train_root_path = def_path + '/train'\n",
    "test_csv_path = def_path + '/test/labels_test.csv'\n",
    "test_root_path = def_path + '/test'\n",
    "test_label_path =  def_path + '/test/test_label_run_th1_test.csv'\n",
    "predicted_label_path = def_path + '/test/predicted_label_run_th1_test.csv'\n",
    "model_path = def_path + '/network_0505_th1.pth'\n",
    "\n",
    "\n",
    "class TumorDatasetTrain(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file , root_dir, transform=None):\n",
    "        self.labels_frame = np.array(pd.read_csv(csv_file, skiprows=1, sep=',', header=None)).astype(np.int)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(idx)+'.png'\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        \"\"\"\n",
    "            !!!Pay attention!!!\n",
    "            The image size is set here\n",
    "            \"\"\"\n",
    "        img = np.empty(shape=(1, 96, 96))\n",
    "        img[0, :, :] = (img_as_float(io.imread(img_path)) - 0.5)/0.5\n",
    "        label = np.array([self.labels_frame[idx,1]-1])\n",
    "        train_sample = {'image': img, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            train_sample = self.transform(train_sample)\n",
    "        return train_sample\n",
    "\n",
    "\n",
    "class TumorDatasetTest(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file , root_dir, transform=None):\n",
    "        self.labels_frame = np.array(pd.read_csv(csv_file, skiprows= 1, sep=',', header= None)).astype(np.int)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(idx) + '.png'\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        \"\"\"\n",
    "            !!!Pay attention!!!\n",
    "            The image size is set here\n",
    "            \"\"\"\n",
    "        img = np.empty(shape=(1, 96, 96))\n",
    "        img[0, :, :] = (img_as_float(io.imread(img_path)) - 0.5)/0.5\n",
    "        label = np.array([self.labels_frame[idx, 1]-1])\n",
    "        test_sample = {'image': img, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            test_sample = self.transform(test_sample)\n",
    "        return test_sample\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, labels = sample['image'], sample['label']\n",
    "        return {'image': torch.from_numpy(image), 'label': torch.LongTensor(labels)}\n",
    "\n",
    "\n",
    "train_dataset = TumorDatasetTrain(csv_file=train_csv_path, root_dir=train_root_path,\n",
    "                                  transform=transforms.Compose([ToTensor()]))\n",
    "test_dataset = TumorDatasetTest(csv_file=test_csv_path, root_dir=test_root_path, transform=transforms.Compose([ToTensor()]))\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate class activation mapping for the top1 prediction\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    \n",
    "#     print(feature_conv.shape)\n",
    "    \n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "def get_cam(net, features_blobs, img_pil, classes, root_img, item):\n",
    "    params = list(net.parameters())\n",
    "    param_temp = np.array(params)\n",
    "    \n",
    "    weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n",
    "   \n",
    "    normalize =  transforms.Normalize([0.5], [0.5])\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    outputs = net(img_pil)  \n",
    "#     probs, idx = torch.max(outputs.data, 1)    \n",
    "    h_x = F.softmax(outputs, dim=1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    print('Iki idx sakdurung ',idx)\n",
    "    probs = probs.cpu().numpy()\n",
    "    idx = idx.cpu().numpy()\n",
    "    print('Iki idx ',idx)\n",
    "\n",
    "    # output: the prediction\n",
    "#     line = '{:.3f} -> {}'.format(probs[0], classes[idx[0]])\n",
    "#     print(line)\n",
    "\n",
    "    CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
    "\n",
    "    # render the CAM and output\n",
    "#     print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0]])\n",
    "    img = cv2.imread(root_img)\n",
    "    height, width, _ = img.shape\n",
    "    CAM = cv2.resize(CAMs[0], (width, height))\n",
    "    heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "    result = heatmap * 0.3 + img * 0.5\n",
    "    cv2.imwrite(def_path + '/coba5' + '/'+str(idx[0])+'_Cam_'+str(item)+'.jpg', result)\n",
    "    print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_blobs = []\n",
    "\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "net._modules.get(final_conv).register_forward_hook(hook_feature)\n",
    "\n",
    "for ii, test_sample in enumerate(dataloader_test):\n",
    "        test_imgs = Variable(test_sample['image']).cuda()\n",
    "        print(\"SEE THIS::: \" , test_imgs.shape)\n",
    "        test_label = Variable(test_sample['label']).cuda()\n",
    "        print(test_label.shape)\n",
    "        root = test_root_path + '/' + str(ii) + '.png'\n",
    "        for i in range(0,test_imgs.size(0)):\n",
    "            features_blobs = []\n",
    "            print(\"now in loop \"+str(i)+\"!!!!!\")\n",
    "            test_imgs_temp = test_imgs[i,:,:,:]\n",
    "            test_imgs_in = test_imgs_temp.unsqueeze(0)\n",
    "            test_label_temp = test_label[i,:]\n",
    "            test_label_in = test_label_temp.unsqueeze(0)\n",
    "            get_cam(net, features_blobs, test_imgs_in, test_label_in, root, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOPED down here!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('FOLD {}'.format(i))\n",
    "    def_path = default_path + '/img_fold{}'.format(i)\n",
    "    train_csv_path = def_path + '/train/labels_train.csv'\n",
    "    train_root_path = def_path + '/train'\n",
    "    test_csv_path = def_path + '/test/labels_test.csv'\n",
    "    test_root_path = def_path + '/test'\n",
    "    test_label_path =  def_path + '/test/test_label_run_th1_test.csv'\n",
    "    predicted_label_path = def_path + '/test/predicted_label_run_th1_test.csv'\n",
    "    model_path = def_path + '/network_0505_th1.pth'\n",
    "    \n",
    "\n",
    "    state_dict = torch.load(def_path + '/network_0505_th1.pth')\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    net.load_state_dict(new_state_dict)\n",
    "    net.eval()\n",
    "    \n",
    "    class TumorDatasetTrain(Dataset):\n",
    "\n",
    "        def __init__(self, csv_file , root_dir, transform=None):\n",
    "            self.labels_frame = np.array(pd.read_csv(csv_file, skiprows=1, sep=',', header=None)).astype(np.int)\n",
    "            self.root_dir = root_dir\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels_frame)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_name = str(idx)+'.png'\n",
    "            img_path = os.path.join(self.root_dir, img_name)\n",
    "            \"\"\"\n",
    "                !!!Pay attention!!!\n",
    "                The image size is set here\n",
    "                \"\"\"\n",
    "            img = np.empty(shape=(1, imsize, imsize))\n",
    "            img[0, :, :] = (img_as_float(io.imread(img_path)) - 0.5)/0.5\n",
    "            label = np.array([self.labels_frame[idx,1]-1])\n",
    "            train_sample = {'image': img, 'label': label}\n",
    "\n",
    "            if self.transform:\n",
    "                train_sample = self.transform(train_sample)\n",
    "            return train_sample\n",
    "\n",
    "\n",
    "    class TumorDatasetTest(Dataset):\n",
    "\n",
    "        def __init__(self, csv_file , root_dir, transform=None):\n",
    "            self.labels_frame = np.array(pd.read_csv(csv_file, skiprows= 1, sep=',', header= None)).astype(np.int)\n",
    "            self.root_dir = root_dir\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels_frame)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_name = str(idx) + '.png'\n",
    "            img_path = os.path.join(self.root_dir, img_name)\n",
    "            \"\"\"\n",
    "                !!!Pay attention!!!\n",
    "                The image size is set here\n",
    "                \"\"\"\n",
    "            img = np.empty(shape=(1, imsize, imsize))\n",
    "            img[0, :, :] = (img_as_float(io.imread(img_path)) - 0.5)/0.5\n",
    "            label = np.array([self.labels_frame[idx, 1]-1])\n",
    "            test_sample = {'image': img, 'label': label}\n",
    "\n",
    "            if self.transform:\n",
    "                test_sample = self.transform(test_sample)\n",
    "            return test_sample\n",
    "\n",
    "\n",
    "    class ToTensor(object):\n",
    "\n",
    "        def __call__(self, sample):\n",
    "            image, labels = sample['image'], sample['label']\n",
    "            return {'image': torch.from_numpy(image), 'label': torch.LongTensor(labels)}\n",
    "\n",
    "\n",
    "    train_dataset = TumorDatasetTrain(csv_file=train_csv_path, root_dir=train_root_path,\n",
    "                                      transform=transforms.Compose([ToTensor()]))\n",
    "    test_dataset = TumorDatasetTest(csv_file=test_csv_path, root_dir=test_root_path, transform=transforms.Compose([ToTensor()]))\n",
    "    dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "    dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "    # generate class activation mapping for the top1 prediction\n",
    "    def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "        # generate the class activation maps upsample to 256x256\n",
    "        size_upsample = (256, 256)\n",
    "\n",
    "    #     print(feature_conv.shape)\n",
    "\n",
    "        bz, nc, h, w = feature_conv.shape\n",
    "        output_cam = []\n",
    "        for idx in class_idx:\n",
    "            cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "            cam = cam.reshape(h, w)\n",
    "            cam = cam - np.min(cam)\n",
    "            cam_img = cam / np.max(cam)\n",
    "            cam_img = np.uint8(255 * cam_img)\n",
    "            output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "        return output_cam\n",
    "\n",
    "    def get_cam(net, features_blobs, img_pil, classes, root_img, item):\n",
    "        params = list(net.parameters())\n",
    "        param_temp = np.array(params)\n",
    "\n",
    "        weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n",
    "\n",
    "        normalize =  transforms.Normalize([0.5], [0.5])\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "\n",
    "        outputs = net(img_pil)  \n",
    "    #     probs, idx = torch.max(outputs.data, 1)    \n",
    "        h_x = F.softmax(outputs, dim=1).data.squeeze()\n",
    "        probs, idx = h_x.sort(0, True)\n",
    "#         print('Iki idx sakdurung ',idx)\n",
    "        probs = probs.cpu().numpy()\n",
    "        idx = idx.cpu().numpy()\n",
    "#         print('iki item: ',item)\n",
    "#         print('Iki idx: ',idx[0])\n",
    "\n",
    "        # output: the prediction\n",
    "    #     line = '{:.3f} -> {}'.format(probs[0], classes[idx[0]])\n",
    "    #     print(line)\n",
    "\n",
    "        CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
    "\n",
    "        # render the CAM and output\n",
    "    #     print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0]])\n",
    "        img = cv2.imread(root_img)\n",
    "        height, width, _ = img.shape\n",
    "        CAM = cv2.resize(CAMs[0], (width, height))\n",
    "        heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "        result = heatmap * 0.3 + img * 0.5\n",
    "        if not os.path.exists(def_path + '/CAM2'):\n",
    "            os.makedirs(def_path + '/CAM2')\n",
    "        cv2.imwrite(def_path + '/CAM2' + '/'+str(idx[0])+'_Cam_'+str(item)+'.jpg', result)\n",
    "        print(\"DONE!\")\n",
    "\n",
    "    features_blobs = []\n",
    "\n",
    "    def hook_feature(module, input, output):\n",
    "        features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "    net._modules.get(final_conv).register_forward_hook(hook_feature)\n",
    "\n",
    "    for ii, test_sample in enumerate(dataloader_test):\n",
    "            test_imgs = Variable(test_sample['image']).cuda()\n",
    "#             print(\"SEE THIS::: \" , test_imgs.shape)\n",
    "            test_label = Variable(test_sample['label']).cuda()\n",
    "#             print(test_label.shape)\n",
    "            root = test_root_path + '/' + str(ii) + '.png'\n",
    "            for i in range(0,test_imgs.size(0)):\n",
    "                features_blobs = []\n",
    "                print(\"now in loop \"+str(i)+\"!!!!!\")\n",
    "                test_imgs_temp = test_imgs[i,:,:,:]\n",
    "                test_imgs_in = test_imgs_temp.unsqueeze(0)\n",
    "                test_label_temp = test_label[i,:]\n",
    "                test_label_in = test_label_temp.unsqueeze(0)\n",
    "                get_cam(net, features_blobs, test_imgs_in, test_label_in, root, i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classes = {0: 'oral', 1: 'cervical'}\n",
    "features_blobs = []\n",
    "\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "net._modules.get(final_conv).register_forward_hook(hook_feature)\n",
    "\n",
    "root = '/home/DL-based-Tumor-Classification/model/utils/37.png'\n",
    "# test_imgs = Image.open(root)\n",
    "\n",
    "\n",
    "for ii, test_sample in enumerate(dataloader_test):\n",
    "        test_imgs = Variable(test_sample['image']).cuda()\n",
    "        print(\"SEE THIS::: \" , test_imgs.shape)\n",
    "        test_label = Variable(test_sample['label']).cuda()\n",
    "        print(test_label.shape)\n",
    "        root = test_root_path + '/' + str(ii) + '.png'\n",
    "        get_cam(net, features_blobs, test_imgs, test_label, root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_label.size())\n",
    "imgs = test_label[0,:]\n",
    "print(imgs.shape)\n",
    "print(imgs.unsqueeze(0).size())\n",
    "unsq = imgs.unsqueeze(0)\n",
    "print(unsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_imgs.size(0)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
