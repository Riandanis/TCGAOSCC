{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import copy\n",
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/home/Various_CAM/grad-cam-pytorch'))\n",
    "\n",
    "import click\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.hub\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "from grad_cam import (\n",
    "    BackPropagation,\n",
    "    Deconvnet,\n",
    "    GradCAM,\n",
    "    GuidedBackPropagation,\n",
    "    occlusion_sensitivity,\n",
    ")\n",
    "\n",
    "# if a model includes LSTM, such as in image captioning,\n",
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import cv2, torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from skimage import img_as_float,io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(cuda):\n",
    "    cuda = cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "    if cuda:\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "    else:\n",
    "        print(\"Device: CPU\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def get_classtable():\n",
    "    classes = []\n",
    "    with open(\"samples/cancer.txt\") as lines:\n",
    "        for line in lines:\n",
    "            line = line.strip().split(\" \", 1)[1]\n",
    "            line = line.split(\", \", 1)[0].replace(\" \", \"_\")\n",
    "            classes.append(line)\n",
    "    return classes\n",
    "\n",
    "\n",
    "def preprocess(image_path, img_size):\n",
    "#     raw_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     1D\n",
    "    raw_image = np.empty(shape=(1, img_size * img_size))\n",
    "    raw_image[0, :] = (img_as_float(io.imread(image_path)) - 0.5)/0.5\n",
    "    \n",
    "#     2D\n",
    "#     raw_image = np.empty(shape=(1, 96, 96))\n",
    "#     raw_image[0, :, :] = (img_as_float(io.imread(image_path)) - 0.5)/0.5\n",
    "    \n",
    "    \n",
    "#     raw_image = cv2.resize(raw_image, (224,) * 2)\n",
    "    image = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )(raw_image[..., ::-1].copy())\n",
    "    image = image.type(torch.cuda.DoubleTensor)\n",
    "    return image, raw_image\n",
    "\n",
    "\n",
    "def save_gradient(filename, gradient):\n",
    "    gradient = gradient.cpu().numpy().transpose(0, 1)\n",
    "    gradient -= gradient.min()\n",
    "    if gradient.max() != 0:\n",
    "        gradient /= gradient.max()\n",
    "        gradient *= 255.0\n",
    "    else:\n",
    "        gradient = 0\n",
    "    cv2.imwrite(filename, np.uint8(gradient))\n",
    "    grads = np.uint8(gradient)\n",
    "    return grads\n",
    "\n",
    "\n",
    "def save_gradcam(filename, gcam, raw_image, paper_cmap=False):\n",
    "    gcam = gcam.cpu().numpy()\n",
    "    gcam = cv2.applyColorMap(np.uint8(gcam * 255.0), cv2.COLORMAP_JET)\n",
    "    # gcam = gcam.astype(np.float) + raw_image.astype(np.float)\n",
    "    if np.nanmax(gcam) != 0:\n",
    "        gcam = (gcam / np.nanmax(gcam)) * 255.0\n",
    "    else:\n",
    "        gcam = 0\n",
    "    cv2.imwrite(filename, np.uint8(gcam))\n",
    "#     cmap = cm.jet_r(gcam)[..., :3] * 255.0\n",
    "#     if paper_cmap:\n",
    "#         alpha = gcam[..., None]\n",
    "#         gcam = alpha * cmap + (1 - alpha) * raw_image\n",
    "#     else:\n",
    "#         gcam = (cmap.astype(np.float) + raw_image.astype(np.float)) / 2\n",
    "#     cv2.imwrite(filename, np.uint8(gcam))\n",
    "\n",
    "\n",
    "def save_sensitivity(filename, maps):\n",
    "    maps = maps.cpu().numpy()\n",
    "    scale = max(maps[maps > 0].max(), -maps[maps <= 0].min())\n",
    "    maps = maps / scale * 0.5\n",
    "    maps += 0.5\n",
    "    maps = cm.bwr_r(maps)[..., :3]\n",
    "    maps = np.uint8(maps * 255.0)\n",
    "    maps = cv2.resize(maps, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "    cv2.imwrite(filename, maps)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# torchvision models\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_of_classes):\n",
    "        super(Net, self).__init__()\n",
    "        # input image channel, output channels, kernel size square convolution\n",
    "        # kernel\n",
    "        # input size = 28 output size = 28\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # input size = 14, output size = 6\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        # input size = 6, output size = 3\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False)\n",
    "        self.vp = nn.MaxPool2d(kernel_size=2, padding=0, stride=2)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256*12*12, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, num_of_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.bn1(self.vp(self.conv1(x))))\n",
    "        x = F.relu(self.bn2(self.vp(self.conv2(x))))\n",
    "        x = F.relu(self.bn3(self.vp(self.conv3(x))))\n",
    "        x = self.drop2D(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#multi_relu\n",
    "class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, num_of_classes):\n",
    "            super(Net, self).__init__()\n",
    "            # input image channel, output channels, kernel size square convolution\n",
    "            # kernel\n",
    "            # input size = 28//96 output size = 28//96\n",
    "            self.conv1 = nn.Conv2d(1, 64, kernel_size=kernel_set, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            self.relu1 = nn.ReLU(inplace = True)\n",
    "            # input size = 14//48 output size = 6//48\n",
    "            self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(128)\n",
    "            self.relu2 = nn.ReLU(inplace = True)\n",
    "            # input size = 6//24, output size = 3//24\n",
    "            self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "            self.bn3 = nn.BatchNorm2d(256)\n",
    "            self.relu3 = nn.ReLU(inplace = True)\n",
    "            self.drop2D = nn.Dropout2d(p=0.25, inplace=False)\n",
    "            self.vp = nn.MaxPool2d(kernel_size=2, padding=0, stride=2)\n",
    "            # an affine operation: y = Wx + b\n",
    "            self.fc1 = nn.Linear(256*12*12, 1024)\n",
    "            self.fc2 = nn.Linear(1024, 512)\n",
    "            self.fc3 = nn.Linear(512, 256)\n",
    "            self.fc4 = nn.Linear(256, num_of_classes)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            in_size = x.size(0)\n",
    "            x = self.relu1(self.bn1(self.vp(self.conv1(x))))\n",
    "            x = self.relu2(self.bn2(self.vp(self.conv2(x))))\n",
    "            x = self.relu3(self.bn3(self.vp(self.conv3(x))))\n",
    "            x = self.drop2D(x)\n",
    "            x = x.view(in_size, -1)\n",
    "            x = self.fc1(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "            x = self.fc4(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 dimension\n",
    "class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, num_of_classes):\n",
    "            super(Net, self).__init__()\n",
    "            # input image channel, output channels, kernel size square convolution\n",
    "            # kernel\n",
    "            # input size = 28//96 output size = 28//96\n",
    "            self.conv1 = nn.Conv1d(1, 64, kernel_size=kernel_set, padding=1)\n",
    "            self.bn1 = nn.BatchNorm1d(64)\n",
    "            self.relu1 = nn.ReLU(inplace = False)\n",
    "            # input size = 14//48 output size = 6//48\n",
    "            self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "            self.bn2 = nn.BatchNorm1d(128)\n",
    "            self.relu2 = nn.ReLU(inplace = False)\n",
    "            # input size = 6//24, output size = 3//24\n",
    "            self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "            self.bn3 = nn.BatchNorm1d(256)\n",
    "            self.relu3 = nn.ReLU(inplace = False)\n",
    "            self.drop = nn.Dropout(p=0.25, inplace=False)\n",
    "            self.vp = nn.MaxPool1d(kernel_size=4, padding=0, stride=4)\n",
    "            # an affine operation: y = Wx + b\n",
    "            self.fc1 = nn.Linear(256*final_feature, 1024)\n",
    "            self.fc2 = nn.Linear(1024, 512)\n",
    "            self.fc3 = nn.Linear(512, 256)\n",
    "            self.fc4 = nn.Linear(256, num_of_classes)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            in_size = x.size(0)\n",
    "            x = self.relu1(self.bn1(self.vp(self.conv1(x))))\n",
    "            x = self.relu2(self.bn2(self.vp(self.conv2(x))))\n",
    "            x = self.relu3(self.bn3(self.vp(self.conv3(x))))\n",
    "            x = self.drop(x)\n",
    "            x = x.view(in_size, -1)\n",
    "            x = self.fc1(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "            x = self.fc4(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @main.command()\n",
    "# @click.option(\"-i\", \"--image-paths\", type=str, multiple=True, required=True)\n",
    "# @click.option(\"-a\", \"--arch\", type=click.Choice(model_names), required=True)\n",
    "# @click.option(\"-t\", \"--target-layer\", type=str, required=True)\n",
    "# @click.option(\"-k\", \"--topk\", type=int, default=2)\n",
    "# @click.option(\"-o\", \"--output-dir\", type=str, default=\"./results\")\n",
    "# @click.option(\"--cuda/--cpu\", default=True)\n",
    "\n",
    "def demo1(image_paths, target_layer, topk, output_dir, cuda, trained_loc, img_size = 98):\n",
    "    \"\"\"\n",
    "    Visualize model responses given multiple images\n",
    "    \"\"\"\n",
    "    arch = 'resnet152'\n",
    "    device = get_device(cuda)\n",
    "\n",
    "    # Synset words\n",
    "    classes = get_classtable()\n",
    "\n",
    "    # Model from torchvision\n",
    "#     model = models.resnet152(pretrained=True)\n",
    "    model = Net(num_of_classes=6)\n",
    "    model = model.double()\n",
    "    \n",
    "    state_dict = torch.load(trained_loc)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print('Weight loaded')\n",
    "#     model.cuda()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Images\n",
    "    images = []\n",
    "    raw_images = []\n",
    "    print(\"Images:\")\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "#         print(\"\\t#{}: {}\".format(i,image_path))\n",
    "        image, raw_image = preprocess(image_path, img_size)\n",
    "        images.append(image)\n",
    "        raw_images.append(raw_image)\n",
    "    print(len(images))\n",
    "    img_count = len(images)\n",
    "    images = torch.stack(images).to(device)\n",
    "    print('before: ',images.size())\n",
    "    images = torch.reshape(images,(img_count,1,img_size*img_size))\n",
    "    print('after: ',images.size())\n",
    "    \n",
    "    image_files = os.listdir(folder)\n",
    "    for fichier in image_files[:]: # filelist[:] makes a copy of filelist.\n",
    "        if not(fichier.endswith(\".png\")):\n",
    "            image_files.remove(fichier)\n",
    "\n",
    "    \"\"\"\n",
    "    Common usage:\n",
    "    1. Wrap your model with visualization classes defined in grad_cam.py\n",
    "    2. Run forward() with images\n",
    "    3. Run backward() with a list of specific classes\n",
    "    4. Run generate() to export results\n",
    "    \"\"\"\n",
    "\n",
    "    # =========================================================================\n",
    "    print(\"Vanilla Backpropagation:\")\n",
    "\n",
    "    bp = BackPropagation(model=model)\n",
    "    probs, ids = bp.forward(images)\n",
    "\n",
    "#     for i in range(topk):\n",
    "#         # In this example, we specify the high confidence classes\n",
    "#         bp.backward(ids=ids[:, [i]])\n",
    "#         gradients = bp.generate()\n",
    "\n",
    "        # Save results as image files\n",
    "#         for j in range(len(images)):\n",
    "#             print(\"\\t#{}: {} ({:.5f})\".format(image_files[j], classes[ids[j, i]], probs[j, i]))\n",
    "\n",
    "#             save_gradient(\n",
    "#                 filename=osp.join(\n",
    "#                     output_dir,\n",
    "#                     \"{}-{}-vanilla-{}.png\".format(classes[ids[j, i]], image_files[j], arch ),\n",
    "#                 ),\n",
    "#                 gradient=gradients[j],\n",
    "#             )\n",
    "\n",
    "    # Remove all the hook function in the \"model\"\n",
    "    bp.remove_hook()\n",
    "\n",
    "#     # =========================================================================\n",
    "#     print(\"Deconvolution:\")\n",
    "\n",
    "#     deconv = Deconvnet(model=model)\n",
    "#     _ = deconv.forward(images)\n",
    "\n",
    "#     for i in range(topk):\n",
    "#         deconv.backward(ids=ids[:, [i]])\n",
    "#         gradients = deconv.generate()\n",
    "\n",
    "#         for j in range(len(images)):\n",
    "# #             print(\"\\t#{}: {} ({:.5f})\".format(image_files[j], classes[ids[j, i]], probs[j, i]))\n",
    "\n",
    "#             save_gradient(\n",
    "#                 filename=osp.join(\n",
    "#                     output_dir,\n",
    "#                     \"{}-{}-deconvnet-{}.png\".format(classes[ids[j, i]], image_files[j], arch, ),\n",
    "#                 ),\n",
    "#                 gradient=gradients[j],\n",
    "#             )\n",
    "\n",
    "#     deconv.remove_hook()\n",
    "\n",
    "    # =========================================================================\n",
    "    print(\"Grad-CAM/Guided Backpropagation/Guided Grad-CAM:\")\n",
    "\n",
    "    gcam = GradCAM(model=model)\n",
    "    _ = gcam.forward(images)\n",
    "\n",
    "    gbp = GuidedBackPropagation(model=model)\n",
    "    _ = gbp.forward(images)\n",
    "    \n",
    "\n",
    "    for i in range(topk):\n",
    "        # Guided Backpropagation\n",
    "        gbp.backward(ids=ids[:, [i]])\n",
    "        gradients = gbp.generate()\n",
    "\n",
    "        # Grad-CAM\n",
    "        gcam.backward(ids=ids[:, [i]])\n",
    "        regions = gcam.generate(target_layer=target_layer)\n",
    "        \n",
    "        for j in range(len(images)):\n",
    "#             print(\"\\t#{}: {} ({:.5f})\".format(image_files[j], classes[ids[j, i]], probs[j, i]))\n",
    "            \n",
    "            # Guided Backpropagation\n",
    "            save_gradient(\n",
    "                filename=osp.join(\n",
    "                    output_dir,\n",
    "                    \"guided_{}_{}_{:.3f}.png\".format(classes[ids[j, i]], image_files[j], probs[j,i]),\n",
    "                ),\n",
    "                gradient=gradients[j],\n",
    "            )\n",
    "#             print(classes[ids[j, i]],image_files[j])\n",
    "            # Guided Grad-CAM\n",
    "            save_gradient(\n",
    "                filename=osp.join(\n",
    "                    output_dir,\n",
    "                    \"guided-gradcam_{}_{}_{:.3f}_{}.png\".format(\n",
    "                        classes[ids[j, i]], image_files[j], probs[j,i], target_layer \n",
    "                    ),\n",
    "                ),\n",
    "                gradient=torch.mul(regions, gradients)[j],\n",
    "            )\n",
    "            \n",
    "#             Grad-CAM\n",
    "            save_gradcam(\n",
    "                filename=osp.join(\n",
    "                    output_dir,\n",
    "                    \"gradcam_{}_{}_{:.3f}_{}.png\".format(\n",
    "                        classes[ids[j, i]], image_files[j], probs[j,i], target_layer \n",
    "                    ),\n",
    "                ),\n",
    "                gcam=regions[j, 0],\n",
    "                raw_image=raw_images[j],\n",
    "            )\n",
    "    \n",
    "def demoguided(image_paths, target_layer, topk, output_dir, cuda, trained_loc):\n",
    "    \"\"\"\n",
    "    Visualize model responses given multiple images\n",
    "    \"\"\"\n",
    "    arch = 'resnet152'\n",
    "    device = get_device(cuda)\n",
    "\n",
    "    # Synset words\n",
    "    classes = get_classtable()\n",
    "\n",
    "    # Model from torchvision\n",
    "#     model = models.resnet152(pretrained=True)\n",
    "    model = Net(num_of_classes=6)\n",
    "    model = model.double()\n",
    "    \n",
    "    state_dict = torch.load(trained_loc)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print('Weight loaded')\n",
    "#     model.cuda()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Images\n",
    "    images = []\n",
    "    raw_images = []\n",
    "    print(\"Images:\")\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "#         print(\"\\t#{}: {}\".format(i,image_path))\n",
    "        image, raw_image = preprocess(image_path)\n",
    "        images.append(image)\n",
    "        raw_images.append(raw_image)\n",
    "    print(len(images))\n",
    "    images = torch.stack(images).to(device)\n",
    "    \n",
    "    image_files = os.listdir(folder)\n",
    "    for fichier in image_files[:]: # filelist[:] makes a copy of filelist.\n",
    "        if not(fichier.endswith(\".png\")):\n",
    "            image_files.remove(fichier)\n",
    "\n",
    "    \"\"\"\n",
    "    Common usage:\n",
    "    1. Wrap your model with visualization classes defined in grad_cam.py\n",
    "    2. Run forward() with images\n",
    "    3. Run backward() with a list of specific classes\n",
    "    4. Run generate() to export results\n",
    "    \"\"\"\n",
    "\n",
    "    # =========================================================================\n",
    "    print(\"Vanilla Backpropagation:\")\n",
    "\n",
    "    bp = BackPropagation(model=model)\n",
    "    probs, ids = bp.forward(images)\n",
    "\n",
    "    for i in range(topk):\n",
    "        # In this example, we specify the high confidence classes\n",
    "        bp.backward(ids=ids[:, [i]])\n",
    "        gradients = bp.generate()\n",
    "\n",
    "        # Save results as image files\n",
    "#         for j in range(len(images)):\n",
    "# #             print(\"\\t#{}: {} ({:.5f})\".format(image_files[j], classes[ids[j, i]], probs[j, i]))\n",
    "\n",
    "#             save_gradient(\n",
    "#                 filename=osp.join(\n",
    "#                     output_dir,\n",
    "#                     \"{}-{}-vanilla-{}.png\".format(classes[ids[j, i]], image_files[j], arch ),\n",
    "#                 ),\n",
    "#                 gradient=gradients[j],\n",
    "#             )\n",
    "\n",
    "    # Remove all the hook function in the \"model\"\n",
    "    bp.remove_hook()\n",
    "\n",
    "# #     # =========================================================================\n",
    "    print(\"Deconvolution:\")\n",
    "\n",
    "    deconv = Deconvnet(model=model)\n",
    "    _ = deconv.forward(images)\n",
    "\n",
    "    for i in range(topk):\n",
    "        deconv.backward(ids=ids[:, [i]])\n",
    "        gradients = deconv.generate()\n",
    "\n",
    "#         for j in range(len(images)):\n",
    "# #             print(\"\\t#{}: {} ({:.5f})\".format(image_files[j], classes[ids[j, i]], probs[j, i]))\n",
    "\n",
    "#             save_gradient(\n",
    "#                 filename=osp.join(\n",
    "#                     output_dir,\n",
    "#                     \"{}-{}-deconvnet-{}.png\".format(classes[ids[j, i]], image_files[j], arch, ),\n",
    "#                 ),\n",
    "#                 gradient=gradients[j],\n",
    "#             )\n",
    "\n",
    "    deconv.remove_hook()\n",
    "\n",
    "#     # =========================================================================\n",
    "    print(\"Grad-CAM/Guided Backpropagation/Guided Grad-CAM:\")\n",
    "\n",
    "    gcam = GradCAM(model=model)\n",
    "    _ = gcam.forward(images)\n",
    "\n",
    "    gbp = GuidedBackPropagation(model=model)\n",
    "    _ = gbp.forward(images)\n",
    "    \n",
    "\n",
    "    for i in range(topk):\n",
    "        # Guided Backpropagation\n",
    "        gbp.backward(ids=ids[:, [i]])\n",
    "        gradients = gbp.generate()\n",
    "\n",
    "        # Grad-CAM\n",
    "        gcam.backward(ids=ids[:, [i]])\n",
    "        regions = gcam.generate(target_layer=target_layer)\n",
    "        \n",
    "        for j in range(len(images)):\n",
    "#             print(\"\\t#{}: {} ({:.5f})\".format(image_files[j], classes[ids[j, i]], probs[j, i]))\n",
    "            \n",
    "#             # Guided Backpropagation\n",
    "#             save_gradient(\n",
    "#                 filename=osp.join(\n",
    "#                     output_dir,\n",
    "#                     \"{}_{}_guided_{:.3f}.png\".format(classes[ids[j, i]], image_files[j], probs[j,i]),\n",
    "#                 ),\n",
    "#                 gradient=gradients[j],\n",
    "#             )\n",
    "            \n",
    "            # Guided Grad-CAM\n",
    "            save_gradient(\n",
    "                filename=osp.join(\n",
    "                    output_dir,\n",
    "                    \"{}_{}_guided_gradcam_{:.3f}_{}.png\".format(\n",
    "                        classes[ids[j, i]], image_files[j], probs[j,i], target_layer \n",
    "                    ),\n",
    "                ),\n",
    "                gradient=torch.mul(regions, gradients)[j],\n",
    "            )\n",
    "            \n",
    "#             Grad-CAM\n",
    "#             save_gradcam(\n",
    "#                 filename=osp.join(\n",
    "#                     output_dir,\n",
    "#                     \"{}_{}_gradcam_{:.3f}_{}.png\".format(\n",
    "#                         classes[ids[j, i]], image_files[j], probs[j,i], target_layer \n",
    "#                     ),\n",
    "#                 ),\n",
    "#                 gcam=regions[j, 0],\n",
    "#                 raw_image=raw_images[j],\n",
    "#             )\n",
    "# @main.command()\n",
    "# @click.option(\"-i\", \"--image-paths\", type=str, multiple=True, required=True)\n",
    "# @click.option(\"-o\", \"--output-dir\", type=str, default=\"./results\")\n",
    "# @click.option(\"--cuda/--cpu\", default=True)\n",
    "def demo2(image_paths, output_dir, cuda, trained_loc):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM at different layers of ResNet-152\n",
    "    \"\"\"\n",
    "\n",
    "    device = get_device(cuda)\n",
    "\n",
    "    # Synset words\n",
    "    classes = get_classtable()\n",
    "\n",
    "    # Model\n",
    "    model = Net(num_of_classes=6)\n",
    "    model = model.double()\n",
    "    #load_weight\n",
    "    state_dict = torch.load(trained_loc)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print('Weight loaded')\n",
    "    \n",
    "#     model = models.resnet152(pretrained=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # The four residual layers\n",
    "    target_layers = [\"relu3\",\"conv3\", \"fc1\"]\n",
    "    target_class = 1\n",
    "\n",
    "    # Images\n",
    "    images = []\n",
    "    raw_images = []\n",
    "    print(\"Images:\")\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        print(\"\\t#{}: {}\".format(i, image_path))\n",
    "        image, raw_image = preprocess(image_path)\n",
    "        images.append(image)\n",
    "        raw_images.append(raw_image)\n",
    "    images = torch.stack(images).to(device)\n",
    "\n",
    "    gcam = GradCAM(model=model)\n",
    "    probs, ids = gcam.forward(images)\n",
    "    ids_ = torch.LongTensor([[target_class]] * len(images)).to(device)\n",
    "    gcam.backward(ids=ids_)\n",
    "\n",
    "    for target_layer in target_layers:\n",
    "        print(\"Generating Grad-CAM @{}\".format(target_layer))\n",
    "\n",
    "        # Grad-CAM\n",
    "        regions = gcam.generate(target_layer=target_layer)\n",
    "\n",
    "        for j in range(len(images)):\n",
    "            print(\n",
    "                \"\\t#{}: {} ({:.5f})\".format(\n",
    "                    j, classes[target_class], float(probs[ids == target_class])\n",
    "                )\n",
    "            )\n",
    "\n",
    "            save_gradcam(\n",
    "                filename=osp.join(\n",
    "                    output_dir,\n",
    "                    \"{}-{}-gradcam-{}-{}.png\".format(\n",
    "                        j, \"resnet152\", target_layer, classes[target_class]\n",
    "                    ),\n",
    "                ),\n",
    "                gcam=regions[j, 0],\n",
    "                raw_image=raw_images[j],\n",
    "            )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "default_path = \"/home/DL-based-Tumor-Classification/Datasets/Newest_case/Oral+Carcinoma\"\n",
    "def_path = default_path + '/img_fold0'\n",
    "train_csv_path = def_path + '/train/labels_train.csv'\n",
    "train_root_path = def_path + '/train'\n",
    "test_csv_path = def_path + '/test/labels_test.csv'\n",
    "test_root_path = def_path + '/test'\n",
    "test_label_path =  def_path + '/test/test_label_run_th1_test.csv'\n",
    "predicted_label_path = def_path + '/test/predicted_label_run_th1_test.csv'\n",
    "model_path = def_path + '/network_0505_th1.pth'\n",
    "\n",
    "\n",
    "class TumorDatasetTrain(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file , root_dir, transform=None):\n",
    "        self.labels_frame = np.array(pd.read_csv(csv_file, skiprows=1, sep=',', header=None)).astype(np.int)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(idx)+'.png'\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        \"\"\"\n",
    "            !!!Pay attention!!!\n",
    "            The image size is set here\n",
    "            \"\"\"\n",
    "        img = np.empty(shape=(1, 96, 96))\n",
    "        img[0, :, :] = (img_as_float(io.imread(img_path)) - 0.5)/0.5\n",
    "        label = np.array([self.labels_frame[idx,1]-1])\n",
    "        train_sample = {'image': img, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            train_sample = self.transform(train_sample)\n",
    "        return train_sample\n",
    "\n",
    "\n",
    "class TumorDatasetTest(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file , root_dir, transform=None):\n",
    "        self.labels_frame = np.array(pd.read_csv(csv_file, skiprows= 1, sep=',', header= None)).astype(np.int)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(idx) + '.png'\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        \"\"\"\n",
    "            !!!Pay attention!!!\n",
    "            The image size is set here\n",
    "            \"\"\"\n",
    "        img = np.empty(shape=(1, 96, 96))\n",
    "        img[0, :, :] = (img_as_float(io.imread(img_path)) - 0.5)/0.5\n",
    "        label = np.array([self.labels_frame[idx, 1]-1])\n",
    "        test_sample = {'image': img, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            test_sample = self.transform(test_sample)\n",
    "        return test_sample\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, labels = sample['image'], sample['label']\n",
    "        return {'image': torch.from_numpy(image), 'label': torch.LongTensor(labels)}\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 400\n",
    "learning_rate = 0.0001\n",
    "\n",
    "train_dataset = TumorDatasetTrain(csv_file=train_csv_path, root_dir=train_root_path,\n",
    "                                  transform=transforms.Compose([ToTensor()]))\n",
    "test_dataset = TumorDatasetTest(csv_file=test_csv_path, root_dir=test_root_path, transform=transforms.Compose([ToTensor()]))\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# @click.group()\n",
    "# @click.pass_context\n",
    "# def main(ctx):\n",
    "#     image_paths = \"/home/DL-based-Tumor-Classification/Datasets/trial_2nd_8843_true_feature/img_fold8/test/\"\n",
    "#     target_layer = \"conv3\"\n",
    "# model_names = 'resnet152'\n",
    "# model_names = sorted(\n",
    "#     name\n",
    "#     for name in models.__dict__\n",
    "#     if name.islower() and not name.startswith(\"__\") and callable(models.__dict__[name])\n",
    "# )\n",
    "output_dir = \"/home/Various_CAM/grad-cam-pytorch/on_cancer_3/\"\n",
    "image_paths = \"/home/DL-based-Tumor-Classification/Datasets/Newest_case/Oral+Carcinoma/img_fold0/test/0.png\"\n",
    "folder = \"/home/DL-based-Tumor-Classification/Datasets/Newest_case/Oral+Carcinoma/img_fold0/test/\"\n",
    "target_layer = \"conv3\"\n",
    "topk = 3\n",
    "cuda = True\n",
    "image_files = os.listdir(folder)\n",
    "for fichier in image_files[:]: # filelist[:] makes a copy of filelist.\n",
    "    if not(fichier.endswith(\".png\")):\n",
    "        image_files.remove(fichier)\n",
    "for i, name in enumerate(image_files):\n",
    "    image_files[i] = folder + name \n",
    "# print(image_files)\n",
    "demo1(image_files, target_layer, topk, output_dir, cuda)\n",
    "                \n",
    "\n",
    "# for ii, test_sample in enumerate(dataloader_test):\n",
    "#             test_imgs = Variable(test_sample['image']).cuda()\n",
    "# #             print(\"SEE THIS::: \" , test_imgs.shape)\n",
    "#             test_label = Variable(test_sample['label']).cuda()\n",
    "# #             print(test_label.shape)\n",
    "#             root = test_root_path + '/' + str(ii) + '.png'\n",
    "#             for i in range(0,test_imgs.size(0)):\n",
    "#                 features_blobs = []\n",
    "#                 print(\"now in loop \"+str(i)+\"!!!!!\")\n",
    "#                 test_imgs_temp = test_imgs[i,:,:,:]\n",
    "#                 test_imgs_in = test_imgs_temp.unsqueeze(0)\n",
    "#                 test_label_temp = test_label[i,:]\n",
    "#                 test_label_in = test_label_temp.unsqueeze(0)\n",
    "# #                 get_cam(net, features_blobs, test_imgs_in, test_label_in, root, i)\n",
    "#                 demo1(test_imgs_in, target_layer, topk, output_dir, cuda)\n",
    "#                 break\n",
    "\n",
    "#     print(\"Mode:\", ctx.invoked_subcommand)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# @click.group()\n",
    "# @click.pass_context\n",
    "# def main(ctx):\n",
    "#     image_paths = \"/home/DL-based-Tumor-Classification/Datasets/trial_2nd_8843_true_feature/img_fold8/test/\"\n",
    "#     target_layer = \"conv3\"\n",
    "# model_names = 'resnet152'\n",
    "# model_names = sorted(\n",
    "#     name\n",
    "#     for name in models.__dict__\n",
    "#     if name.islower() and not name.startswith(\"__\") and callable(models.__dict__[name])\n",
    "# )\n",
    "output_dir = \"/home/Various_CAM/grad-cam-pytorch/on_cancer_1/\"\n",
    "image_paths = \"/home/DL-based-Tumor-Classification/Datasets/Newest_case/Other+Cervical/img_fold0/test/0.png\"\n",
    "folder = \"/home/DL-based-Tumor-Classification/Datasets/Newest_case/Other+Cervical/img_fold0/test/\"\n",
    "target_layer = \"conv3\"\n",
    "topk = 2\n",
    "cuda = True\n",
    "image_files = os.listdir(folder)\n",
    "\n",
    "demo1(image_paths, target_layer, topk, output_dir, cuda)\n",
    "                \n",
    "\n",
    "# for ii, test_sample in enumerate(dataloader_test):\n",
    "#             test_imgs = Variable(test_sample['image']).cuda()\n",
    "# #             print(\"SEE THIS::: \" , test_imgs.shape)\n",
    "#             test_label = Variable(test_sample['label']).cuda()\n",
    "# #             print(test_label.shape)\n",
    "#             root = test_root_path + '/' + str(ii) + '.png'\n",
    "#             for i in range(0,test_imgs.size(0)):\n",
    "#                 features_blobs = []\n",
    "#                 print(\"now in loop \"+str(i)+\"!!!!!\")\n",
    "#                 test_imgs_temp = test_imgs[i,:,:,:]\n",
    "#                 test_imgs_in = test_imgs_temp.unsqueeze(0)\n",
    "#                 test_label_temp = test_label[i,:]\n",
    "#                 test_label_in = test_label_temp.unsqueeze(0)\n",
    "# #                 get_cam(net, features_blobs, test_imgs_in, test_label_in, root, i)\n",
    "#                 demo1(test_imgs_in, target_layer, topk, output_dir, cuda)\n",
    "#                 break\n",
    "\n",
    "#     print(\"Mode:\", ctx.invoked_subcommand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
